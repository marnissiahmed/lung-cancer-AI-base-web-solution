{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import measure\n",
    "import cv2\n",
    "import base64\n",
    "from PIL import Image as im\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import measure\n",
    "\n",
    "def get_coord(mask_3d, image):\n",
    "    # Set default values\n",
    "    center = []\n",
    "    diameter = []\n",
    "    mask_3d = mask_3d.squeeze()\n",
    "    print(mask_3d.shape)\n",
    "    # Label connected components in the 3D mask\n",
    "    labeled_mask = measure.marching_cubes(mask_3d)\n",
    "    \n",
    "    # Extract properties of connected components\n",
    "    props = measure.regionprops(labeled_mask)\n",
    "  \n",
    "    \n",
    "    # Loop through the properties and extract the circle properties\n",
    "    for prop in props:\n",
    "        # Ignore small components\n",
    "        if prop.area < 100:\n",
    "            continue\n",
    "\n",
    "        # Calculate centroid coordinates\n",
    "        \n",
    "        centroid = prop.centroid\n",
    "        print(centroid)\n",
    "        c = image.TransformContinuousIndexToPhysicalPoint(centroid)  # Swap x and y for physical coordinates\n",
    "        center.append(c)\n",
    "\n",
    "        # Calculate equivalent diameter\n",
    "        diameter.append(prop.equivalent_diameter_area * image.GetSpacing()[0])\n",
    "\n",
    "    if len(center) == 0:\n",
    "        print(\"No circles found.\")\n",
    "        return None, None\n",
    "\n",
    "    return center, diameter\n",
    "\n",
    "# Assuming you have the 3D mask and image object\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hu_transform(img):\n",
    "    window_level = -600\n",
    "    window_width = 1500\n",
    "\n",
    "    # Apply the windowing filter\n",
    "    window_filter = sitk.IntensityWindowingImageFilter()\n",
    "    window_filter.SetWindowMinimum(window_level - window_width/2.0)\n",
    "    window_filter.SetWindowMaximum(window_level + window_width/2.0)\n",
    "    window_filter.SetOutputMinimum(0)\n",
    "    window_filter.SetOutputMaximum(255)\n",
    "    image_windowed = window_filter.Execute(img)\n",
    "    return image_windowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import io\n",
    "import base64\n",
    "from PIL import Image as im\n",
    "\n",
    "def predict(image):\n",
    "    result = {\n",
    "        \"state\": None,\n",
    "        \"nodules\":None\n",
    "        \n",
    "    }\n",
    "    \n",
    "    deeplab = tf.keras.models.load_model(\"deeplabv3plus.h5\", compile=False)\n",
    "    image = hu_transform(image)\n",
    "    arr_3d = sitk.GetArrayFromImage(image)\n",
    "    arr_3d = arr_3d / 255\n",
    "    \n",
    "    # Predict on the entire 3D volume\n",
    "    mask_3d = deeplab.predict(arr_3d.reshape(arr_3d.shape[0],arr_3d.shape[1],arr_3d.shape[2],1), batch_size=1)\n",
    "    \n",
    "    \n",
    "    # Perform processing on the predicted mask and get circle information\n",
    "    \n",
    "    \n",
    "    mask_c = sitk.GetImageFromArray(mask_3d.reshape(image.GetSize()))\n",
    "  \n",
    "    \n",
    "    # Overlay mask on the input image\n",
    "    \n",
    "    \n",
    "    # Convert image to PIL format for further processing\n",
    "   \n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "    return mask_3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"D:/fin_de_etude/data/subset7/1.3.6.1.4.1.14519.5.2.1.6279.6001.106379658920626694402549886949.mhd\"  # Replace with the path to your volume image\n",
    "image = sitk.ReadImage(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 29s 105ms/step\n"
     ]
    }
   ],
   "source": [
    "img = predict(image)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Only 2-D and 3-D images supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\fin_de_etude\\data\\pfe\\deep learning\\test\\trys.ipynb Cell 7\u001b[0m in \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fin_de_etude/data/pfe/deep%20learning/test/trys.ipynb#X13sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m center, diameter\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fin_de_etude/data/pfe/deep%20learning/test/trys.ipynb#X13sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# Example usage\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/fin_de_etude/data/pfe/deep%20learning/test/trys.ipynb#X13sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m center, diameter \u001b[39m=\u001b[39m extract_sphere_properties(img)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fin_de_etude/data/pfe/deep%20learning/test/trys.ipynb#X13sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCenter:\u001b[39m\u001b[39m\"\u001b[39m, center)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fin_de_etude/data/pfe/deep%20learning/test/trys.ipynb#X13sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDiameter:\u001b[39m\u001b[39m\"\u001b[39m, diameter)\n",
      "\u001b[1;32md:\\fin_de_etude\\data\\pfe\\deep learning\\test\\trys.ipynb Cell 7\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fin_de_etude/data/pfe/deep%20learning/test/trys.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         largest_component \u001b[39m=\u001b[39m labeled_mask \u001b[39m==\u001b[39m label\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fin_de_etude/data/pfe/deep%20learning/test/trys.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Calculate sphere properties for the largest component\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/fin_de_etude/data/pfe/deep%20learning/test/trys.ipynb#X13sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m properties \u001b[39m=\u001b[39m measure\u001b[39m.\u001b[39;49mregionprops(largest_component)[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fin_de_etude/data/pfe/deep%20learning/test/trys.ipynb#X13sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m center \u001b[39m=\u001b[39m properties\u001b[39m.\u001b[39mcentroid\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fin_de_etude/data/pfe/deep%20learning/test/trys.ipynb#X13sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m diameter \u001b[39m=\u001b[39m properties\u001b[39m.\u001b[39mequivalent_diameter\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\skimage\\measure\\_regionprops.py:1251\u001b[0m, in \u001b[0;36mregionprops\u001b[1;34m(label_image, intensity_image, cache, coordinates, extra_properties)\u001b[0m\n\u001b[0;32m   1003\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Measure properties of labeled image regions.\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m \n\u001b[0;32m   1005\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1247\u001b[0m \n\u001b[0;32m   1248\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m \u001b[39mif\u001b[39;00m label_image\u001b[39m.\u001b[39mndim \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m):\n\u001b[1;32m-> 1251\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mOnly 2-D and 3-D images supported.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   1253\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(label_image\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39minteger):\n\u001b[0;32m   1254\u001b[0m     \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(label_image\u001b[39m.\u001b[39mdtype, \u001b[39mbool\u001b[39m):\n",
      "\u001b[1;31mTypeError\u001b[0m: Only 2-D and 3-D images supported."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage import measure\n",
    "\n",
    "def extract_sphere_properties(volume):\n",
    "    # Threshold the volume to create a binary mask\n",
    "    mask = volume > 0  # Adjust the threshold as needed\n",
    "\n",
    "    # Label connected components in the mask\n",
    "    labeled_mask, num_labels = measure.label(mask, connectivity=3, return_num=True)\n",
    "\n",
    "    # Find the largest connected component (assuming it corresponds to the sphere)\n",
    "    largest_component = None\n",
    "    largest_component_volume = 0\n",
    "    for label in range(1, num_labels + 1):\n",
    "        component_volume = np.sum(labeled_mask == label)\n",
    "        if component_volume > largest_component_volume:\n",
    "            largest_component_volume = component_volume\n",
    "            largest_component = labeled_mask == label\n",
    "\n",
    "    # Calculate sphere properties for the largest component\n",
    "    properties = measure.regionprops(largest_component)[0]\n",
    "    center = properties.centroid\n",
    "    diameter = properties.equivalent_diameter\n",
    "\n",
    "    return center, diameter\n",
    "\n",
    "# Example usage\n",
    "\n",
    "\n",
    "center, diameter = extract_sphere_properties(img)\n",
    "\n",
    "print(\"Center:\", center)\n",
    "print(\"Diameter:\", diameter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(214, 512, 512)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'ndim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\fin_de_etude\\data\\pfe\\deep learning\\test\\trys.ipynb Cell 8\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/fin_de_etude/data/pfe/deep%20learning/test/trys.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(img\u001b[39m>\u001b[39m\u001b[39m0.5\u001b[39m ,\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/fin_de_etude/data/pfe/deep%20learning/test/trys.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m get_coord(mask,image)\n",
      "\u001b[1;32md:\\fin_de_etude\\data\\pfe\\deep learning\\test\\trys.ipynb Cell 8\u001b[0m in \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fin_de_etude/data/pfe/deep%20learning/test/trys.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m labeled_mask \u001b[39m=\u001b[39m measure\u001b[39m.\u001b[39mmarching_cubes(mask_3d)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fin_de_etude/data/pfe/deep%20learning/test/trys.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Extract properties of connected components\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/fin_de_etude/data/pfe/deep%20learning/test/trys.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m props \u001b[39m=\u001b[39m measure\u001b[39m.\u001b[39;49mregionprops(labeled_mask)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fin_de_etude/data/pfe/deep%20learning/test/trys.ipynb#W6sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Loop through the properties and extract the circle properties\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fin_de_etude/data/pfe/deep%20learning/test/trys.ipynb#W6sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m prop \u001b[39min\u001b[39;00m props:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fin_de_etude/data/pfe/deep%20learning/test/trys.ipynb#W6sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39m# Ignore small components\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\skimage\\measure\\_regionprops.py:1250\u001b[0m, in \u001b[0;36mregionprops\u001b[1;34m(label_image, intensity_image, cache, coordinates, extra_properties)\u001b[0m\n\u001b[0;32m   1001\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mregionprops\u001b[39m(label_image, intensity_image\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, cache\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   1002\u001b[0m                 coordinates\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m, extra_properties\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1003\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Measure properties of labeled image regions.\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m \n\u001b[0;32m   1005\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1247\u001b[0m \n\u001b[0;32m   1248\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1250\u001b[0m     \u001b[39mif\u001b[39;00m label_image\u001b[39m.\u001b[39;49mndim \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m):\n\u001b[0;32m   1251\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mOnly 2-D and 3-D images supported.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   1253\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(label_image\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39minteger):\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'ndim'"
     ]
    }
   ],
   "source": [
    "mask = np.where(img>0.5 ,1,0)\n",
    "get_coord(mask,image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gamer\\AppData\\Local\\Temp\\ipykernel_11860\\669658688.py:14: DeprecationWarning: Please use `find_objects` from the `scipy.ndimage` namespace, the `scipy.ndimage.measurements` namespace is deprecated.\n",
      "  objects = ndimage.measurements.find_objects(mask)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'centroid'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\fin_de_etude\\data\\pfe\\deep learning\\test\\trys.ipynb Cell 9\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fin_de_etude/data/pfe/deep%20learning/test/trys.ipynb#X10sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     cells\u001b[39m.\u001b[39mappend((slices, label, properties\u001b[39m.\u001b[39mcentroid))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fin_de_etude/data/pfe/deep%20learning/test/trys.ipynb#X10sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m cells\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/fin_de_etude/data/pfe/deep%20learning/test/trys.ipynb#X10sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m cells \u001b[39m=\u001b[39m find_cells(mask)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fin_de_etude/data/pfe/deep%20learning/test/trys.ipynb#X10sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mfor\u001b[39;00m cell \u001b[39min\u001b[39;00m cells:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fin_de_etude/data/pfe/deep%20learning/test/trys.ipynb#X10sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m      \u001b[39mprint\u001b[39m(cell[\u001b[39m0\u001b[39m], cell[\u001b[39m1\u001b[39m], cell[\u001b[39m2\u001b[39m], cell[\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39mmajor_axis_length)\n",
      "\u001b[1;32md:\\fin_de_etude\\data\\pfe\\deep learning\\test\\trys.ipynb Cell 9\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fin_de_etude/data/pfe/deep%20learning/test/trys.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m   label \u001b[39m=\u001b[39m \u001b[39mobject\u001b[39m[\u001b[39m1\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fin_de_etude/data/pfe/deep%20learning/test/trys.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m   properties \u001b[39m=\u001b[39m measure\u001b[39m.\u001b[39mregionprops(mask[slices])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/fin_de_etude/data/pfe/deep%20learning/test/trys.ipynb#X10sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m   cells\u001b[39m.\u001b[39mappend((slices, label, properties\u001b[39m.\u001b[39;49mcentroid))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/fin_de_etude/data/pfe/deep%20learning/test/trys.ipynb#X10sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mreturn\u001b[39;00m cells\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'centroid'"
     ]
    }
   ],
   "source": [
    "from scipy import ndimage\n",
    "\n",
    "def find_cells(mask):\n",
    "  \"\"\"Finds cells in a 3D mask.\n",
    "\n",
    "  Args:\n",
    "    mask: A 3D NumPy array representing the mask.\n",
    "\n",
    "  Returns:\n",
    "    A list of cells, where each cell is a tuple of (slices, label, center).\n",
    "  \"\"\"\n",
    "\n",
    "  mask = mask.squeeze()\n",
    "  objects = ndimage.measurements.find_objects(mask)\n",
    "  cells = []\n",
    "  for object in objects:\n",
    "    slices = object[0]\n",
    "    label = object[1]\n",
    "    properties = measure.regionprops(mask[slices])\n",
    "    cells.append((slices, label, properties.centroid))\n",
    "  return cells\n",
    "\n",
    "\n",
    "cells = find_cells(mask)\n",
    "for cell in cells:\n",
    "     print(cell[0], cell[1], cell[2], cell[2].major_axis_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(center))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "545a6d87df314298b7fbf2d97a754a58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[], gradient_opacity=0.22, point_sets=[], rendered_image=<itk.itkImagePython.itkImageSS3; pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itk\n",
    "from itkwidgets import view\n",
    "itk_image = itk.imread(\"D:/fin_de_etude/data/subset0/1.3.6.1.4.1.14519.5.2.1.6279.6001.105756658031515062000744821260.mhd\")\n",
    "\n",
    "view(itk_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
